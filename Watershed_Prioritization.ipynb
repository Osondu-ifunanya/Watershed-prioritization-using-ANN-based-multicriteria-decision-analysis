{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr3N06ZyfUhSBlkouTlYun",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Osondu-ifunanya/Watershed-prioritization-using-ANN-based-multicriteria-decision-analysis/blob/main/Watershed_Prioritization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_sMMQsmFk3v"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# -----------------------------\n",
        "# 1) Synthetic data generation\n",
        "# -----------------------------\n",
        "n_ws = 150  # number of sub-watersheds\n",
        "ws_id = [f\"WS_{i:03d}\" for i in range(1, n_ws+1)]\n",
        "\n",
        "# Generate synthetic criteria (ranges chosen to look realistic)\n",
        "slope_mean = np.random.uniform(2, 25, n_ws)                 # degrees (cost)\n",
        "relief_ratio = np.random.uniform(0.02, 0.25, n_ws)          # (cost)\n",
        "drainage_density = np.random.uniform(0.5, 3.5, n_ws)        # km/km^2 (cost)\n",
        "stream_frequency = np.random.uniform(0.2, 4.0, n_ws)        # no./km^2 (cost)\n",
        "rainfall = np.random.uniform(600, 1800, n_ws)               # mm/yr (cost for erosion/flood risk)\n",
        "soil_erod_k = np.random.uniform(0.05, 0.45, n_ws)           # USLE K-factor (cost)\n",
        "ndvi = np.random.uniform(0.1, 0.8, n_ws)                    # (benefit)\n",
        "forest_pct = np.random.uniform(5, 85, n_ws)                 # % area (benefit)\n",
        "builtup_pct = np.random.uniform(0, 40, n_ws)                # % area (cost)\n",
        "curve_number = np.random.uniform(55, 92, n_ws)              # CN (cost)\n",
        "runoff_coeff = np.random.uniform(0.05, 0.75, n_ws)          # (cost)\n",
        "dist_stream_km = np.random.uniform(0.1, 6.0, n_ws)          # mean distance to streams (benefit)\n",
        "lith_perm_index = np.random.uniform(0.1, 0.9, n_ws)         # lithological permeability (benefit)\n",
        "gw_potential = np.random.uniform(0.1, 0.9, n_ws)            # groundwater potential (benefit)\n",
        "pop_density = np.random.uniform(50, 2500, n_ws)             # persons/km^2 (cost)\n",
        "erosion_risk = np.random.uniform(0.1, 1.0, n_ws)            # composite index (cost)\n",
        "\n",
        "# Assemble into DataFrame\n",
        "features = pd.DataFrame({\n",
        "    \"slope_mean_deg\": slope_mean,\n",
        "    \"relief_ratio\": relief_ratio,\n",
        "    \"drainage_density\": drainage_density,\n",
        "    \"stream_frequency\": stream_frequency,\n",
        "    \"rainfall_mm\": rainfall,\n",
        "    \"soil_erod_k\": soil_erod_k,\n",
        "    \"ndvi\": ndvi,\n",
        "    \"forest_pct\": forest_pct,\n",
        "    \"builtup_pct\": builtup_pct,\n",
        "    \"curve_number\": curve_number,\n",
        "    \"runoff_coeff\": runoff_coeff,\n",
        "    \"dist_stream_km\": dist_stream_km,\n",
        "    \"lith_perm_index\": lith_perm_index,\n",
        "    \"gw_potential\": gw_potential,\n",
        "    \"pop_density\": pop_density,\n",
        "    \"erosion_risk\": erosion_risk\n",
        "}, index=ws_id)\n",
        "\n",
        "# Directions: +1 = benefit (higher is better -> lowers priority), -1 = cost (higher is worse -> increases priority)\n",
        "directions = {\n",
        "    \"slope_mean_deg\": -1,\n",
        "    \"relief_ratio\": -1,\n",
        "    \"drainage_density\": -1,\n",
        "    \"stream_frequency\": -1,\n",
        "    \"rainfall_mm\": -1,          # assume higher rainfall worsens erosion/flood risk\n",
        "    \"soil_erod_k\": -1,\n",
        "    \"ndvi\": +1,\n",
        "    \"forest_pct\": +1,\n",
        "    \"builtup_pct\": -1,\n",
        "    \"curve_number\": -1,\n",
        "    \"runoff_coeff\": -1,\n",
        "    \"dist_stream_km\": +1,       # farther from streams = less immediate risk\n",
        "    \"lith_perm_index\": +1,\n",
        "    \"gw_potential\": +1,\n",
        "    \"pop_density\": -1,\n",
        "    \"erosion_risk\": -1\n",
        "}\n",
        "\n",
        "# Create a \"true\" latent priority score from plausible relationships (higher score = higher priority)\n",
        "# Weights sum not required; add noise to simulate label uncertainty.\n",
        "true_w = {\n",
        "    \"slope_mean_deg\": 0.12,\n",
        "    \"relief_ratio\": 0.08,\n",
        "    \"drainage_density\": 0.10,\n",
        "    \"stream_frequency\": 0.07,\n",
        "    \"rainfall_mm\": 0.06,\n",
        "    \"soil_erod_k\": 0.12,\n",
        "    \"ndvi\": -0.10,\n",
        "    \"forest_pct\": -0.08,\n",
        "    \"builtup_pct\": 0.06,\n",
        "    \"curve_number\": 0.08,\n",
        "    \"runoff_coeff\": 0.07,\n",
        "    \"dist_stream_km\": -0.04,\n",
        "    \"lith_perm_index\": -0.03,\n",
        "    \"gw_potential\": -0.04,\n",
        "    \"pop_density\": 0.05,\n",
        "    \"erosion_risk\": 0.18\n",
        "}\n",
        "\n",
        "# Normalize each feature (z-score) to make the linear synthetic function stable\n",
        "f_mu = features.mean(axis=0)\n",
        "f_sd = features.std(axis=0).replace(0, 1.0)\n",
        "z = (features - f_mu) / f_sd\n",
        "\n",
        "# Latent true priority score (linear combo in z-space + noise)\n",
        "latent = np.zeros(n_ws)\n",
        "for k, w in true_w.items():\n",
        "    latent += w * z[k].values\n",
        "noise = np.random.normal(0, 0.25, n_ws)\n",
        "priority_true = latent + noise\n",
        "\n",
        "# Scale to 0..1 for readability\n",
        "priority_min, priority_max = priority_true.min(), priority_true.max()\n",
        "priority_true_01 = (priority_true - priority_min) / (priority_max - priority_min)\n",
        "\n",
        "# Priority classes by terciles\n",
        "q1, q2 = np.quantile(priority_true_01, [1/3, 2/3])\n",
        "def class_from_score(s):\n",
        "    if s < q1: return \"Low\"\n",
        "    if s < q2: return \"Medium\"\n",
        "    return \"High\"\n",
        "\n",
        "priority_class = np.array([class_from_score(s) for s in priority_true_01])\n",
        "\n",
        "# -----------------------------\n",
        "# 2) Train ANN (MLPRegressor)\n",
        "# -----------------------------\n",
        "X = features.values\n",
        "y = priority_true_01  # continuous target (0..1)\n",
        "\n",
        "X_train, X_test, y_train, y_test, id_train, id_test = train_test_split(\n",
        "    X, y, features.index.values, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "# MLP configuration (compact, stable)\n",
        "mlp = MLPRegressor(hidden_layer_sizes=(64, 32),\n",
        "                   activation='relu',\n",
        "                   solver='adam',\n",
        "                   learning_rate_init=1e-3,\n",
        "                   alpha=1e-4,\n",
        "                   max_iter=1500,\n",
        "                   random_state=42)\n",
        "mlp.fit(X_train_s, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = mlp.predict(X_test_s)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "print(f\"ANN test R2 = {r2:.3f}, RMSE = {rmse:.3f}\")\n",
        "\n",
        "# -----------------------------\n",
        "# 3) ANN-driven MCDA weights via permutation importance\n",
        "# -----------------------------\n",
        "perm = permutation_importance(mlp, X_test_s, y_test, n_repeats=15, random_state=42)\n",
        "imp = perm.importances_mean  # can be negative if noise; clip at 0\n",
        "imp = np.clip(imp, 0, None)\n",
        "# Normalize to sum to 1\n",
        "weights_ann = imp / (imp.sum() + 1e-12)\n",
        "weight_table = pd.DataFrame({\n",
        "    \"criterion\": features.columns,\n",
        "    \"ann_weight\": weights_ann\n",
        "}).sort_values(\"ann_weight\", ascending=False)\n",
        "print(\"\\nDerived MCDA weights from ANN permutation importance:\")\n",
        "print(weight_table)\n",
        "\n",
        "# -----------------------------\n",
        "# 4) Compute MCDA composite score (benefit/cost aware)\n",
        "# -----------------------------\n",
        "# Normalize all features with z-score then convert to positive direction using 'directions'\n",
        "Z_all = (features - f_mu) / f_sd\n",
        "\n",
        "# Convert to benefit space: if criterion is cost (-1), multiply by -1 so larger is always better (low priority)\n",
        "benefit_Z = Z_all.copy()\n",
        "for k, d in directions.items():\n",
        "    if d == -1:\n",
        "        benefit_Z[k] = -benefit_Z[k]\n",
        "\n",
        "# Rescale benefit_Z to 0..1 for each criterion (min-max)\n",
        "benefit_01 = (benefit_Z - benefit_Z.min()) / (benefit_Z.max() - benefit_Z.min() + 1e-12)\n",
        "\n",
        "# Weighted sum using ANN-derived weights\n",
        "w_vec = pd.Series(weights_ann, index=features.columns)\n",
        "mcda_score = (benefit_01 * w_vec).sum(axis=1)\n",
        "\n",
        "# Convert MCDA to \"priority\" direction (higher value -> higher priority)\n",
        "# Our benefit_01 means larger is better (lower priority), so invert:\n",
        "mcda_priority = 1.0 - (mcda_score - mcda_score.min()) / (mcda_score.max() - mcda_score.min() + 1e-12)\n",
        "\n",
        "# Rank and classify\n",
        "rank_ann = mlp.predict(scaler.transform(features.values))  # ANN priority (0..1)\n",
        "rank_ann_series = pd.Series(rank_ann, index=features.index, name=\"ann_priority_01\")\n",
        "\n",
        "def class_by_tercile(arr):\n",
        "    q1, q2 = np.quantile(arr, [1/3, 2/3])\n",
        "    return pd.Series(np.where(arr<q1, \"Low\", np.where(arr<q2, \"Medium\", \"High\")),\n",
        "                     index=features.index)\n",
        "\n",
        "ann_class = class_by_tercile(rank_ann_series.values)\n",
        "mcda_class = class_by_tercile(mcda_priority.values)\n",
        "\n",
        "# -----------------------------\n",
        "# 5) Assemble outputs\n",
        "# -----------------------------\n",
        "out = features.copy()\n",
        "out[\"priority_true_01\"] = priority_true_01\n",
        "out[\"priority_true_class\"] = priority_class\n",
        "out[\"ann_priority_01\"] = rank_ann_series\n",
        "out[\"ann_priority_class\"] = ann_class\n",
        "out[\"mcda_priority_01\"] = mcda_priority\n",
        "out[\"mcda_priority_class\"] = mcda_class\n",
        "\n",
        "# Rankings (1 = highest priority)\n",
        "out[\"ann_rank\"] = (-out[\"ann_priority_01\"]).rank(method=\"dense\").astype(int)\n",
        "out[\"mcda_rank\"] = (-out[\"mcda_priority_01\"]).rank(method=\"dense\").astype(int)\n",
        "\n",
        "print(\"\\nTop 10 watersheds by ANN priority:\")\n",
        "print(out.sort_values(\"ann_priority_01\", ascending=False).head(10)[\n",
        "    [\"ann_priority_01\",\"ann_rank\"]\n",
        "])\n",
        "\n",
        "print(\"\\nTop 10 watersheds by MCDA priority:\")\n",
        "print(out.sort_values(\"mcda_priority_01\", ascending=False).head(10)[\n",
        "    [\"mcda_priority_01\",\"mcda_rank\"]\n",
        "])\n",
        "\n",
        "# -----------------------------\n",
        "# 6) Plots\n",
        "# -----------------------------\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.scatter(y_test, y_pred, alpha=0.6)\n",
        "mn, mx = min(y_test.min(), y_pred.min()), max(y_test.max(), y_pred.max())\n",
        "plt.plot([mn, mx], [mn, mx], 'r--', lw=1)\n",
        "plt.xlabel(\"True priority (0..1)\")\n",
        "plt.ylabel(\"ANN predicted priority (0..1)\")\n",
        "plt.title(f\"ANN Performance (RÂ²={r2:.2f}, RMSE={rmse:.2f})\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "weight_table.plot(kind=\"barh\", x=\"criterion\", y=\"ann_weight\", legend=False)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.xlabel(\"ANN-derived weight\")\n",
        "plt.title(\"MCDA Weights from ANN Permutation Importance\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.scatter(out[\"ann_priority_01\"], out[\"mcda_priority_01\"], alpha=0.7)\n",
        "plt.xlabel(\"ANN priority (0..1)\")\n",
        "plt.ylabel(\"MCDA priority (0..1)\")\n",
        "plt.title(\"Agreement: ANN vs ANN-weighted MCDA\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# 7) Export to Excel\n",
        "# -----------------------------\n",
        "with pd.ExcelWriter(\"watershed_prioritization_ann_mcda.xlsx\", engine=\"openpyxl\") as writer:\n",
        "    out.to_excel(writer, sheet_name=\"prioritization\", index=True)\n",
        "    weight_table.to_excel(writer, sheet_name=\"ann_mcda_weights\", index=False)\n",
        "\n",
        "print(\"\\nExported results to: watershed_prioritization_ann_mcda.xlsx\")\n",
        "\n"
      ]
    }
  ]
}